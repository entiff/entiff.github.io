---
layout: post
title:  "2018 NLP Trend"
date:   2019-01-13 18:00:00
author: entiff
categories: etc
---

2019년 1월 12일 naver d2에서 조용래님의 2018 NLP Trend 발표를 듣고 이에 대해 정리한 글입니다. 급하게 받아 적은 글로 실제 발표 내용과 차이가 있을 수 있습니다. 개인적인 해석이 들어가 있어 틀린 부분이 있을 수 있습니다. 지적해주시면 감사하겠습니다 :)

조용래님은 현재 네이버 NLP 대화 챗봇팀에서 근무하고 계십니다. 2018 NLP Trend에 대해서 크게 7개로 나누어 설명해주셨습니다.

### 1. Transformer

Attention module은 중요한 단어에 집중하도록 학습합니다. translation에서는 alignment라는 개념으로 등장했습니다. self-attention은 문장을 이해하기 위해 그 문장 자체를 보고 context vector를 만듭니다. multi-head attention은 여기에서 더 나아가 한 문장에 여러 개의 attention을 걸어 문장의 맥락을 더 잘 이해할 수 있게 만듭니다. [Attention is all you need(2017)](https://arxiv.org/pdf/1706.03762.pdf)에서는 Attention만으로 seq2seq 모델을 만들어 그 자체로 CNN과 RNN계열 모델을 뛰어넘었습니다.

### 2. Pretrained language models

Word Vector라는 개념은 오래 전부터 있었습니다. one-hot encoding이 아닌 distributed representation으로 더 적은 차원에 단어의 정보를 임베딩합니다. 여기서 더 나아가 고정된 word vector를 학습하는 것이 아닌 확률적으로 접근하는 [Dynamic embedding](https://arxiv.org/pdf/1702.08359.pdf) 개념이 등장했습니다. 이 개념을 이용해 언어의 정보를 좀 더 풍부하게 담아낼 수 있게 됐습니다.

Pretrained language model의 일반적인 학습 방식은 한 문장의 일부 단어를 masking하고 이를 예측하도록 합니다. 이러한 학습 방식은 다른 task에도 좋은 영향을 주어 약간의 fine-tuning만으로 좋은 결과를 내게 합니다. 따라서, pretrain된 모델은 앞으로 더 많이 등장할 것이라고 합니다.

### 3. Unsupervied machine translation

기존에 translation task를 풀기 위해서는 Parallel corpus가 필요합니다. 이 corpus를 생성하기 위해서는 매우 많은 자원이 투입되어야 합니다. 따라서 연구자들은 Parallel corpus 없이 연구하는 방법을 고민하고 있습니다. 예를 들어 같은 의미를 가진 한국어 단어와 영어 단어를 같은 latent space에 mapping할 수 있다면 이러한 문제를 해결할 수 있습니다. 실제로는 한국어를 영어로 translation하고 다시 한국어로 translation 했을 때 결과가 같다면 그 단어 혹은 문장이 같은 latent space에 mapping됐다고 볼 수 있습니다. 여기에 noise를 추가한 auto encoder가 사용되고 있다고 합니다.

Vision 분야에서는 이러한 개념이 style transfer라는 키워드로 매우 활발하게 연구되고 있습니다. 따라서, NLP도 좀 더 발전한다면 특정한 문체로 바꿔주는 style tranfer를 기대해 볼 수 있습니다.

### 4. Inductive bias

CNN은 사실 인간의 사전정보가 반영된 모델입니다. 우리가 사진에서 사물을 눈으로 인식한다고 하면 전체가 아닌 일부만으로 판단하기 때문입니다. 이처럼 모델에 사전적인 정보를 주고 학습하게 하는 방법이 활발하게 연구되고 있습니다. 예를 들면 사람이 문서를 읽을 때 집중하는(attention) 패턴과 모델의 attention이 비슷하다면 이는 좋은 모델이라고 볼 수 있습니다. 같은 맥락에서 낮은 layer에서는 POS와 같은 low-level의 정보를, 높은 layer에서는 semantic information을 전달하는 것이 확인되고 있습니다. 이와같은 모델의 해석가능성에 대해서는 대표적으로 [LIME](https://arxiv.org/pdf/1602.04938.pdf?__hstc=200028081.1bb630f9cde2cb5f07430159d50a3c91.1523923200081.1523923200082.1523923200083.1&__hssc=200028081.1.1523923200084&__hsfp=1773666937)이 있습니다.

### 5. Meta-learning

Meta-learning은 적은 데이터로도 쉽게 task를 풀 순 없을까? 하는 접근에서 출발합니다. 사람은 여러가지의 task를 동시에 학습할 수 있습니다. 펜 집기, 콩 집기, 빨대 집기 등은 서로 다른 task이지만 '집기'라는 같은 맥락이 있어 펜을 집을 수 있는 사람은 콩을 한번도 안집어보더라도 금방 집어낼 수 있습니다. 이처럼 언어에서도 상대적으로 적은 데이터를 가진 언어를 다른 언어를 이용해 쉽게 학습하고자 하는 접근법이 발달하고 있습니다. Gradient의 gradient를 학습합니다. 학습 방식을 '학습'해 처음 겪는 task에 대해 좋은 initialization 또는 hyper parameter를 줄 수 있습니다. [참고](https://arxiv.org/pdf/1808.08437.pdf)

![matelearning](https://github.com/shwksl101/shwksl101.github.io/blob/master/images/metalearning.PNG?raw=true)

### 6. QA and reasoning with large documents

SQuAD 1.1v에서는 이미 human-level을 넘어선 모델이 등장했습니다. 바로 [BERT](https://arxiv.org/pdf/1810.04805.pdf)입니다. 최근에는 Bigbird라는 모델이 BERT의 GLUE Benchmark를 뛰어넘으며 많은 관심을 받고 있습니다. 이에 연구자들은 더 어려운 machine reading comprehension에 도전하고 있습니다. Narrative QA dataset은 문서당 약 6만개의 token을 가지고 있습니다. 한 단락 정도에 불과한 SQuAD dataset에 비해 매우 긴 문서입니다.

### 7. Common sense inference datasets

[VCR](https://visualcommonsense.com/)은 매우 재미있는 task를 제시하고 있습니다. [From recognition to cognition: visual commonsense reasoning](https://arxiv.org/pdf/1811.10830.pdf)에서는 visual commonsense를 이해할 수 있는 모델을 이야기합니다. image와 question이 주어지고 이에 대한 answer를 합니다. 그러나 여기서 재밌는 점은 답을 선택한 이유(rationale)에 대해 밝혀야 합니다. 답을 선택한 이유가 적절하다면 모델이 common sense를 학습한 것으로 간주합니다. 이에 대해 grounding - contextualization - reasoning을 제시합니다.

2018 NLP trend를 7가지로 정리해주셨지만 이는 적은 데이터로 학습하기, 다른 task에 transfer하기, realistic challenge로 정리됩니다. NLP에 관심있는 저로써 NLP와 관련된 다양한 연구동향을 알 수 있어서 정말 좋았습니다. 빠르게 발전하고 있는 분야인 만큼 task들이 정말 무섭게 정복되고 있는 것 같네요. 긴 글 읽어주셔서 감사합니다 :)
