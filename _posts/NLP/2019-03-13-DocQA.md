---
layout: post
title:  "Simple and Effective Multi-Paragraph Reading Comprehension"
date:   2019-03-13 12:00:00
author: entiff
categories: NLP
---

[Simple and Effective Multi-Paragraph Reading Comprehension](https://arxiv.org/pdf/1710.10723.pdf)에 대해 정리한 글입니다.

## [Multiple paragraphs selection]

#### 1. 기존 방법

- Confidence score

모든 문단을 한번씩 집어넣고 confidence 점수와 함께 answer span을 뽑아냅니다. 가장 높은 confidence 점수를 나타낸 answer span에서 정답을 추출합니다.

#### 2. 제안한 방법

- TF-IDF paragraph selection

Document에서 정답이 없는 문단들을 포함해 문단들을 sampling합니다.
이때, 질문과 가장 짧은 코사인 거리를 가진 문단을 고릅니다.
다시 말해, 질문과 코사인 유사도가 가장 높은 n개의 문단을 고를 수 있습니다.

## [Handling Noisy Labels]

Answer 단어는 문단 안에서 여러번 등장할 수 있으나, 답변과 관련된 문장은 하나이고 거기서 정답 단어는 더 적게 등장합니다.
따라서, answer span의 시작 토큰과 end 토큰을 독립적으로 예측해야 합니다.
다시 말해, answer span을 고르고 그 안에서 정답 단어를 예측하도록 해야 noise를 제거할 수 있습니다.

## [Confidence method]

#### 1. Shared-normalization

독립적으로 문단마다 연산합니다. 문단 마다 모든 토큰에 대해 answer start token logit값을 계산하게 합니다.
p개의 문단이 있고, 각 문단 마다 `n_j`개의 단어가 있습니다 (`j C P`)
결국 p개의 문단에 대한 n_j개의 logit값을 구하고 이를 softmax layer로 보내면 모든 문단을 고려하게 됩니다.

#### 2. Merge

문단을 구분하는 token을 추가하고 모든 문단을 병합합니다.

#### 3. No-Answer Option

각각의 문단에 대해 no-answer라는 답변을 할 수 있게 만듭니다.
start token과 end token의 softmax loss에 no-answer 항을 추가합니다. token 항에 계수를 붙여 답이 있으면 1 없으면 0으로 만듭니다.
no-answer항에는 1-계수를 붙여 답이 없는 경우 no-answer항을 살리고 token항을 없앱니다. 분모에는 no-answer항을 추가합니다.

no-answer항의 점수는 start token attention, end token attention, no-answer token attention의 concat 벡터를 2 layer network에
넣고 ReLU activation의 결과 값을 점수로 사용합니다.

#### 4. Sigmoid

start token과 end token을 문단별로 softmax layer에 흘려 보내지 않고 각 token의 점수를 sigmoid 항에 흘립니다.
loss는 cross entropy를 사용해 독립적으로 계산해 모든 문단을 고려하도록 합니다.
